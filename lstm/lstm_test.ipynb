{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm_test.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNPvIaJ4s0wh8x0lFNYx23z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YanhuaZhang516/memory-representation-pomdp/blob/main/lstm_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xqz55Vt9ynHO"
      },
      "source": [
        "#### import Tensosflow in to the program:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLKRZgsPwtUk",
        "outputId": "6846abea-b8ce-489a-a9b3-5832f8dc4714"
      },
      "source": [
        "%tensorflow_version 1.x\r\n",
        "import tensorflow as tf\r\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTjlss5bNh4m"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3r29fzo2JZY"
      },
      "source": [
        "### (1) lstm_1\r\n",
        "#### set the lstm by myself\r\n",
        "\r\n",
        "#### 1. set some hyper-parameters \r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGJILgDW2NO9"
      },
      "source": [
        "# define some hyper-parameters about lstm\r\n",
        "\r\n",
        "# Number of neurons in the hidden state varaibles\r\n",
        "num_nodes= 128\r\n",
        "# Number of data points in a batch we process in validation 每一批次训练多少样本\r\n",
        "\r\n",
        "# and the number for training data set is 4* batch_size\r\n",
        "batch_size_in = 4\r\n",
        "batch_size_va = 1\r\n",
        "# Number of time steps we unrolling for durinngg optimization\r\n",
        "# Trucated-BPTT 中使用的时间步数，步数越高，性能越好，但也会增加内存开销和计算时间\r\n",
        "num_unrolling = 10\r\n",
        "output_size=1\r\n",
        "\r\n",
        "dropout = 0.2 # we use dropout here to avoid overfitting problem"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkX7Le1OLl3-"
      },
      "source": [
        "#### 2. define the parameters about LSTM\r\n",
        "##### 1. input gate: ix, im, ib\r\n",
        "##### 2. forget gate: \r\n",
        "##### 3. output gate: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hPA0C0lLdlZ"
      },
      "source": [
        "# set the placeholders for the training data and validaiton data\r\n",
        "tf. reset_default_graph()\r\n",
        "# Input gate: ix, im, ib(it) - How much memory to write to cell state\r\n",
        "# tf.truncated_normal(shape, mean, stddev) \r\n",
        "input_size = 2\r\n",
        "output_size = 1\r\n",
        "# connect the current input to the input gate\r\n",
        "ix = tf.Variable(tf.random.truncated_normal([input_size, num_nodes], stddev = 0.02))\r\n",
        "# connect the previous hidden state to the input gate\r\n",
        "\r\n",
        "im = tf.Variable(tf.random.truncated_normal([num_nodes, num_nodes], stddev = 0.02))\r\n",
        "# bias of the input gate\r\n",
        "ib = tf.Variable(tf.random.uniform([1*batch_size_in, num_nodes], -0.02, 0.02))\r\n",
        "\r\n",
        "# forget gate: fx, fm, fb(ft) - How much memory to discard from cell state\r\n",
        "fx = tf.Variable(tf.random.truncated_normal([input_size, num_nodes], stddev = 0.02))\r\n",
        "# connect the previous hidden state to the forget gate\r\n",
        "fm = tf.Variable(tf.random.truncated_normal([num_nodes, num_nodes], stddev = 0.02))\r\n",
        "# bias of the forget gate\r\n",
        "fb = tf.Variable(tf.random.uniform([1*batch_size_in, num_nodes], -0.02, 0.02))\r\n",
        "\r\n",
        "# Candidate value(c~t）- Used to compute the current cell state\r\n",
        "\r\n",
        "cx = tf.Variable(tf.random.truncated_normal([input_size, num_nodes], stddev = 0.02))\r\n",
        "# connect the previous hidden state to the candidate\r\n",
        "cm = tf.Variable(tf.random.truncated_normal([num_nodes, num_nodes], stddev = 0.02))\r\n",
        "# bias of the candidate\r\n",
        "cb = tf.Variable(tf.random.uniform([1*batch_size_in, num_nodes], -0.02, 0.02))\r\n",
        "\r\n",
        "# Output gate - How much memory to output from the cell state\r\n",
        "\r\n",
        "ox = tf.Variable(tf.random.truncated_normal([input_size, num_nodes], stddev = 0.02))\r\n",
        "# connect the previous hidden state to the candidate\r\n",
        "om = tf.Variable(tf.random.truncated_normal([num_nodes, num_nodes], stddev = 0.02))\r\n",
        "# bias of the candidate\r\n",
        "ob = tf.Variable(tf.random.uniform([1*batch_size_in, num_nodes], -0.02, 0.02))\r\n",
        "\r\n",
        "# In the end, we get output y through softmax\r\n",
        "w = tf.Variable(tf.random.truncated_normal([num_nodes, output_size], stddev = 0.02))\r\n",
        "b = tf.Variable(tf.random.uniform([output_size], -0.02, 0.02))\r\n",
        "\r\n",
        "# Variables saving state across unrollings\r\n",
        "\r\n",
        "# Hiddens state\r\n",
        "saved_output = tf.Variable(tf.zeros([batch_size_in,num_nodes]), trainable= False, name='train_hidden')\r\n",
        "# cell state\r\n",
        "saved_state = tf.Variable(tf.zeros([batch_size_in,num_nodes]), trainable= False, name='train_cell')\r\n",
        "# prediction state\r\n",
        "saved_labels = tf.Variable(tf.zeros([batch_size_in,output_size]), trainable= False, name='train_labels')\r\n",
        "\r\n",
        "# same varaibles for validation phase\r\n",
        "saved_validate_output = tf.Variable(tf.zeros([batch_size_va,num_nodes]), trainable= False, name='validate_hidden')\r\n",
        "saved_validate_state = tf.Variable(tf.zeros([batch_size_va,num_nodes]), trainable= False, name='validate_cell')\r\n",
        "\r\n",
        "# same varaibles for test phase\r\n",
        "saved_test_output = tf.Variable(tf.zeros([1,num_nodes]), trainable= False, name='test_hidden')\r\n",
        "saved_test_state = tf.Variable(tf.zeros([1,num_nodes]), trainable= False, name='test_cell')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEaCcHYTedhO"
      },
      "source": [
        "#### 3. define the LSTM cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikhdJqpbeYOg"
      },
      "source": [
        "def lstm_cell(input_x , hidden_state , cell_state):\r\n",
        "  \"\"\"\r\n",
        "  input:\r\n",
        "  input_x: The input data at time t, the size is [batchsize, input_size]\r\n",
        "  ix:[input_size, num_nodes]\r\n",
        "  \r\n",
        "  input_size:[obs, action]\r\n",
        "  hidden_state: the hidden state h_(t-1) from the previous time t-1\r\n",
        "  cell_state: the cell state c_(t-1) from the previous timt t-1\r\n",
        "\r\n",
        "  output: return the output y_t , cell state c_t\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  input_gate = tf.sigmoid(tf.matmul(input_x, ix)+ tf.matmul(hidden_state,im) + ib)\r\n",
        "\r\n",
        "  forget_gate =tf.sigmoid(tf.matmul(input_x, fx)+ tf.matmul(hidden_state,fm) + fb)\r\n",
        "  # the candiate cell state c~t\r\n",
        "  update = tf.matmul(input_x, cx) + tf.matmul(hidden_state, cm) + cb\r\n",
        "  # the current cell state c_t\r\n",
        "  c_t = forget_gate* cell_state + input_gate * tf.tanh(update)\r\n",
        "\r\n",
        "  output_gate = tf.sigmoid(tf.matmul(input_x, ox) + tf.matmul(hidden_state, om) + ob)\r\n",
        "  # new hidden state\r\n",
        "  h_t = output_gate *tf.tanh(c_t)\r\n",
        "  \r\n",
        "  return h_t, c_t\r\n",
        "  "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBRNQ-fSXCL4"
      },
      "source": [
        "# test the function of lstm_cell:\r\n",
        "input_x=np.float32(np.random.rand(8).reshape(4,2))\r\n",
        "hidden_state = np.ones((4,128),dtype=np.float32)\r\n",
        "cell_state = np.ones((4,128),dtype=np.float32)\r\n",
        "update = tf.matmul(input_x, cx) + tf.matmul(hidden_state, cm) + cb\r\n",
        "\r\n",
        "h_t, c_t = lstm_cell(input_x , hidden_state , cell_state)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tl_VHabt9hYB"
      },
      "source": [
        "### Defining Inputs and Outputs\r\n",
        "Here, we define two different types of inputs\r\n",
        "\r\n",
        "\r\n",
        "*   Training inputs (batch_size>1, with unrolling)\r\n",
        "*   Validation inputs (batch_size > 1, with unrolling)\r\n",
        "*   Test inputs (batch_size =1, no unrolling)\r\n",
        "\r\n",
        "Trainig set: Validation set =4:1\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyTR68hl9gCd"
      },
      "source": [
        "train_inputs, train_labels = [], []\r\n",
        "valid_inputs, valid_labels = [], []\r\n",
        "\r\n",
        "# defining unrolled training data placeholders 按时间展开\r\n",
        "for x in range(num_unrolling):\r\n",
        "  train_inputs.append(tf.placeholder(tf.float32, shape=[batch_size_in, input_size], name = 'train_inputs_%d'%x))\r\n",
        "  train_labels.append(tf.placeholder(tf.float32, shape=[batch_size_in, 1], name = 'train_labels_%d'%x))\r\n",
        "  # validation data placeholders\r\n",
        "  valid_inputs = tf.placeholder(tf.float32, shape=[batch_size_va, input_size], name = 'validate_inputs')\r\n",
        "  valid_labels = tf.placeholder(tf.float32, shape=[batch_size_va, 1], name = 'validate_labels')\r\n",
        "\r\n",
        "test_input = tf.placeholder(tf.float32, shape=[1])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rTKazJPaWYc"
      },
      "source": [
        "#### load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAe_3pT7Ndaj"
      },
      "source": [
        "df = pd.read_csv('trajectory_10_grids.csv')\r\n",
        "df = df.apply(pd.to_numeric, errors='ignore')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTaXEwmDTEnD",
        "outputId": "2c2eda01-757b-4d9a-ef4c-88e24164ab82"
      },
      "source": [
        "print(df.dtypes)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unnamed: 0     int64\n",
            "trajectory     int64\n",
            "inputs        object\n",
            "state          int64\n",
            "dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AKAHYBRQLz5"
      },
      "source": [
        "def generate_batch_data(num_unrolling):\r\n",
        "  batch_inputs=[]\r\n",
        "  batch_labels=[]\r\n",
        "  for i in range(num_unrolling):\r\n",
        "    # time steps\r\n",
        "    inputs=[]\r\n",
        "    labels=[]\r\n",
        "    for j in range(4):\r\n",
        "      # batch size \r\n",
        "      action= np.float32(df.loc[df['trajectory']==(j+1)]['inputs'][250*j+i][1])\r\n",
        "      obs = np.float32(df.loc[df['trajectory']==(j+1)]['inputs'][250*j+i][3])\r\n",
        "      label = np.float32(df.loc[df['trajectory']==(j+1)]['state'][250*j+i])\r\n",
        "      input=[action, obs]\r\n",
        "      inputs.append(input)\r\n",
        "      \r\n",
        "      labels.append(label)\r\n",
        " \r\n",
        "    inputs=np.array(inputs)\r\n",
        "    labels = np.array(labels)\r\n",
        "    batch_inputs.append(inputs)\r\n",
        "    batch_labels.append(labels)\r\n",
        "\r\n",
        "\r\n",
        "  return batch_inputs, batch_labels"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awudnyW0woru"
      },
      "source": [
        "# test the batch size \r\n",
        "batch_inputs, batch_labels=generate_batch_data(num_unrolling=10)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPoaDRLh8m94"
      },
      "source": [
        "def train_lstm(lr, data_inputs, data_labels):\r\n",
        " \r\n",
        "  outputs = []\r\n",
        "  # the prediction part\r\n",
        "  pre_outputs = []\r\n",
        "  labels = []\r\n",
        "  # at each step per unrolling\r\n",
        "  # hidden state (batch_size, 128)\r\n",
        "  output = saved_output\r\n",
        "  # cell state (batch_size, 128)\r\n",
        "  cell_state = saved_state\r\n",
        "  label = saved_labels\r\n",
        "\r\n",
        "  # compute the hidden state (output) and cell state (state)\r\n",
        "  # recursively for all the steps in unrolling\r\n",
        "  for i in range(len(train_inputs)):\r\n",
        "    # the output for 1 time step\r\n",
        "    output, cell_state = lstm_cell(input_x=train_inputs[i], hidden_state=output, cell_state= cell_state)\r\n",
        "    output = tf.nn.dropout(output, keep_prob=1.0-dropout)\r\n",
        "    # append each computed output value\r\n",
        "    pre_output = tf.nn.softmax(tf.matmul(output, w) +b)\r\n",
        "    pre_outputs.append(pre_output)\r\n",
        "\r\n",
        "  # we add control dependencies here to gurantee the right oder of calculation\r\n",
        "  with tf.control_dependencies([saved_output.assign(output), saved_state.assign(cell_state)]): \r\n",
        "\r\n",
        "    loss = tf.reduce_mean(tf.square(tf.reshape(pre_outputs,[-1]) - tf.reshape(train_labels,[-1])))\r\n",
        "  \r\n",
        "  # Adam Optimizer, and gradient clipping, here we use clipping to avoid the gradien exploation\r\n",
        "  optimizer = tf.train.AdamOptimizer(learning_rate=lr)\r\n",
        "  gradients, variables = zip(*optimizer.compute_gradients(loss))\r\n",
        "  gradients, _ = tf.clip_by_global_norm(gradients, 5.0)\r\n",
        "  # update the weights and bias\r\n",
        "  train_op = optimizer.apply_gradients(zip(gradients, variables))\r\n",
        "  # save the model \r\n",
        "  saver= tf.train.Saver(tf.global_variables())\r\n",
        "\r\n",
        "  # generate the feed_dict\r\n",
        "  feed_dict = {}\r\n",
        "  for ui, (data,label) in enumerate(zip(data_inputs, data_labels)):\r\n",
        "    feed_dict[train_inputs[ui]]=data\r\n",
        "    feed_dict[train_labels[ui]] = label.reshape(4,1)\r\n",
        "\r\n",
        "  with tf.Session() as sess:\r\n",
        "    sess.run(tf.global_variables_initializer())\r\n",
        "    # reset the training for 1000 times\r\n",
        "    for i in range(1000):\r\n",
        "      \r\n",
        "      _, loss_ = sess.run([train_op, loss], feed_dict = feed_dict)\r\n",
        "      # each 10 steps save once the parameters\r\n",
        "      if i % 10==0:\r\n",
        "        print(i, loss_)\r\n",
        "        print(\"save the model:\", saver.save(sess,'lstm.model'))\r\n",
        "   \r\n",
        "          "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wh9LTJ4Hf9tQ",
        "outputId": "aa44ea48-7421-4a8c-e3db-f016b050a28c"
      },
      "source": [
        "train_lstm(lr=1.5e-5,data_inputs=batch_inputs, data_labels=batch_labels)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 209.125\n",
            "save the model: lstm.model\n",
            "10 209.125\n",
            "save the model: lstm.model\n",
            "20 209.125\n",
            "save the model: lstm.model\n",
            "30 209.125\n",
            "save the model: lstm.model\n",
            "40 209.125\n",
            "save the model: lstm.model\n",
            "50 209.125\n",
            "save the model: lstm.model\n",
            "60 209.125\n",
            "save the model: lstm.model\n",
            "70 209.125\n",
            "save the model: lstm.model\n",
            "80 209.125\n",
            "save the model: lstm.model\n",
            "90 209.125\n",
            "save the model: lstm.model\n",
            "100 209.125\n",
            "save the model: lstm.model\n",
            "110 209.125\n",
            "save the model: lstm.model\n",
            "120 209.125\n",
            "save the model: lstm.model\n",
            "130 209.125\n",
            "save the model: lstm.model\n",
            "140 209.125\n",
            "save the model: lstm.model\n",
            "150 209.125\n",
            "save the model: lstm.model\n",
            "160 209.125\n",
            "save the model: lstm.model\n",
            "170 209.125\n",
            "save the model: lstm.model\n",
            "180 209.125\n",
            "save the model: lstm.model\n",
            "190 209.125\n",
            "save the model: lstm.model\n",
            "200 209.125\n",
            "save the model: lstm.model\n",
            "210 209.125\n",
            "save the model: lstm.model\n",
            "220 209.125\n",
            "save the model: lstm.model\n",
            "230 209.125\n",
            "save the model: lstm.model\n",
            "240 209.125\n",
            "save the model: lstm.model\n",
            "250 209.125\n",
            "save the model: lstm.model\n",
            "260 209.125\n",
            "save the model: lstm.model\n",
            "270 209.125\n",
            "save the model: lstm.model\n",
            "280 209.125\n",
            "save the model: lstm.model\n",
            "290 209.125\n",
            "save the model: lstm.model\n",
            "300 209.125\n",
            "save the model: lstm.model\n",
            "310 209.125\n",
            "save the model: lstm.model\n",
            "320 209.125\n",
            "save the model: lstm.model\n",
            "330 209.125\n",
            "save the model: lstm.model\n",
            "340 209.125\n",
            "save the model: lstm.model\n",
            "350 209.125\n",
            "save the model: lstm.model\n",
            "360 209.125\n",
            "save the model: lstm.model\n",
            "370 209.125\n",
            "save the model: lstm.model\n",
            "380 209.125\n",
            "save the model: lstm.model\n",
            "390 209.125\n",
            "save the model: lstm.model\n",
            "400 209.125\n",
            "save the model: lstm.model\n",
            "410 209.125\n",
            "save the model: lstm.model\n",
            "420 209.125\n",
            "save the model: lstm.model\n",
            "430 209.125\n",
            "save the model: lstm.model\n",
            "440 209.125\n",
            "save the model: lstm.model\n",
            "450 209.125\n",
            "save the model: lstm.model\n",
            "460 209.125\n",
            "save the model: lstm.model\n",
            "470 209.125\n",
            "save the model: lstm.model\n",
            "480 209.125\n",
            "save the model: lstm.model\n",
            "490 209.125\n",
            "save the model: lstm.model\n",
            "500 209.125\n",
            "save the model: lstm.model\n",
            "510 209.125\n",
            "save the model: lstm.model\n",
            "520 209.125\n",
            "save the model: lstm.model\n",
            "530 209.125\n",
            "save the model: lstm.model\n",
            "540 209.125\n",
            "save the model: lstm.model\n",
            "550 209.125\n",
            "save the model: lstm.model\n",
            "560 209.125\n",
            "save the model: lstm.model\n",
            "570 209.125\n",
            "save the model: lstm.model\n",
            "580 209.125\n",
            "save the model: lstm.model\n",
            "590 209.125\n",
            "save the model: lstm.model\n",
            "600 209.125\n",
            "save the model: lstm.model\n",
            "610 209.125\n",
            "save the model: lstm.model\n",
            "620 209.125\n",
            "save the model: lstm.model\n",
            "630 209.125\n",
            "save the model: lstm.model\n",
            "640 209.125\n",
            "save the model: lstm.model\n",
            "650 209.125\n",
            "save the model: lstm.model\n",
            "660 209.125\n",
            "save the model: lstm.model\n",
            "670 209.125\n",
            "save the model: lstm.model\n",
            "680 209.125\n",
            "save the model: lstm.model\n",
            "690 209.125\n",
            "save the model: lstm.model\n",
            "700 209.125\n",
            "save the model: lstm.model\n",
            "710 209.125\n",
            "save the model: lstm.model\n",
            "720 209.125\n",
            "save the model: lstm.model\n",
            "730 209.125\n",
            "save the model: lstm.model\n",
            "740 209.125\n",
            "save the model: lstm.model\n",
            "750 209.125\n",
            "save the model: lstm.model\n",
            "760 209.125\n",
            "save the model: lstm.model\n",
            "770 209.125\n",
            "save the model: lstm.model\n",
            "780 209.125\n",
            "save the model: lstm.model\n",
            "790 209.125\n",
            "save the model: lstm.model\n",
            "800 209.125\n",
            "save the model: lstm.model\n",
            "810 209.125\n",
            "save the model: lstm.model\n",
            "820 209.125\n",
            "save the model: lstm.model\n",
            "830 209.125\n",
            "save the model: lstm.model\n",
            "840 209.125\n",
            "save the model: lstm.model\n",
            "850 209.125\n",
            "save the model: lstm.model\n",
            "860 209.125\n",
            "save the model: lstm.model\n",
            "870 209.125\n",
            "save the model: lstm.model\n",
            "880 209.125\n",
            "save the model: lstm.model\n",
            "890 209.125\n",
            "save the model: lstm.model\n",
            "900 209.125\n",
            "save the model: lstm.model\n",
            "910 209.125\n",
            "save the model: lstm.model\n",
            "920 209.125\n",
            "save the model: lstm.model\n",
            "930 209.125\n",
            "save the model: lstm.model\n",
            "940 209.125\n",
            "save the model: lstm.model\n",
            "950 209.125\n",
            "save the model: lstm.model\n",
            "960 209.125\n",
            "save the model: lstm.model\n",
            "970 209.125\n",
            "save the model: lstm.model\n",
            "980 209.125\n",
            "save the model: lstm.model\n",
            "990 209.125\n",
            "save the model: lstm.model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqHztuHClBdl"
      },
      "source": [
        "# validation part\r\n",
        "def prediction(inputs,labels):\r\n",
        "  outputs=[]\r\n",
        "  output = saved_validate_output\r\n",
        "  cell_state = saved_validate_state\r\n",
        "  for i in range(len(inputs)):\r\n",
        "    output, cell_state = lstm_cell(input_x=i, hidden_state=output, cell_state= cell_state)\r\n",
        "    output = tf.nn.dropout(output, keep_prob=1.0-dropout)\r\n",
        "    outputs.append(output)\r\n",
        "    print(\"the predicted state:\", output)\r\n",
        "    print(\"the real state:\", labels[i])\r\n",
        "  \r\n",
        "  # calculat the MSE\r\n",
        "  loss = tf.reduce_mean(tf.square(tf.reshape(outputs,[-1]) - tf.reshape(labels,[-1])))\r\n",
        "  \r\n",
        "\r\n",
        "  return loss\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9y1SNBvu6i0M"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}